# Today - 2025-03-24 (Mon)

## Scrub
- CNN 기반 꽃 이미지 분류 프로젝트 중간 발표 준비
- 데이터셋 분석 및 모델 비교 실험 진행

## Learned

### 프로젝트 개요
- 주제: 꽃 이미지 분류를 위한 CNN 사전 훈련 모델 비교 실험
- 사용 데이터셋: [Flowers Dataset (Kaggle)](https://www.kaggle.com/datasets/imsparsh/flowers-dataset/code)
- 주요 목표: 모델 성능 비교 및 최적 모델 선택, 향후 DB 연동 구조 설계

### 데이터셋 설명
- 클래스: daisy, dandelion, rose, sunflower, tulip (총 5종)
- 특징: 색상, 텍스처, 중심 구조 등 시각적 구분이 명확함
- 선택 이유: 실험에서 분류 기준이 명확하고, 컬러 기반 세부 분류 가능성 존재

### 모델 비교 실험
- 사전 훈련 모델 4종 비교 (모두 ImageNet 기반 전이 학습 적용)

| 모델 | 구조 대표성 | 최종 val_accuracy | 특징 |
| --- | --- | --- | --- |
| **VGG16** | 전통적인 CNN 구조 | **0.83** | 안정적인 성능, 기준선(Baseline) |
| **ResNet50** | Residual 구조 | 0.48± | val 성능 불안정 (오버핏 의심) |
| **MobileNetV2** | 경량화, 속도 최적 | 0.84 | 과적합 경향, 높은 train acc |
| **EfficientNetB0** | 해상도/깊이/너비 균형 | 0.25 | 학습 불가, 초기화/학습률 문제 |

- 선택 모델: **VGG16** (현재 Fine Tuning 중, 특정 Epoch에서 튐 현상 발생)

### 실험 방법
- 학습 환경: Google Colab
- 실험 방식: 4개 모델 동일 조건에서 전이 학습
- 사용 기법: EarlyStopping, Image Augmentation(회전 등) 예정
- 추가: 잘못된 이미지 필터링 (ex. 꽃 데이터에 버스 사진 포함 등)

### 용어 정리
- **Baseline**: 성능 비교 기준 모델
- **Residual Block**: 깊은 네트워크 학습을 위한 shortcut 구조 (ResNet)
- **Depthwise Convolution**: 채널별 처리로 연산량 감소 (MobileNet)
- **Trade-off**: 속도 vs 정확도 간 균형 이슈

## Keep
- 단순하지만 성능이 안정적인 모델(VGG16)을 기준선으로 유지
- 실험 시 다양한 시각적 특징(곡선, 색상, 질감 등)을 고려해 모델 구조 선정

## Problem
- EfficientNet 학습 실패 → 초기화 및 학습률 점검 필요
- 특정 epoch에서 튀는 validation loss 문제
- ResNet50 과적합 및 학습 불안정성 확인

## Try
1. VGG16 모델 Fine Tuning 및 Epoch 튜닝
2. 이상 이미지 제거 (Index 기반 필터링) 후 성능 비교
3. 데이터 증강 후 성능 비교 및 과적합 개선
4. 향후 **DB 연동**을 위한 모델 학습-저장-불러오기 구조 설계
5. 최적화 중심 경량 모델(MobileNet 등) 추가 실험 가능성 검토

## 참고자료
- [VGG Transfer Learning](https://www.kaggle.com/code/dipanshurautela2001/transferlearningvgg-0-85-accuracy)
- [Colab 실습 링크](https://colab.research.google.com/drive/1XGcAmKKsuw4-tNx_uEed8ehpvS5kuSA9?authuser=1#scrollTo=X26z5Qb0QzC7)
- [크롤링 참고](https://wikidocs.net/234705)
- [표 정리 자료](https://www.notion.so/1c009fd9adc48094a930cc75e8638b26?pvs=21)
