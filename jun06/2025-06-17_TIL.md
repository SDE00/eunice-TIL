# Today - 2025-06-17 (Tue)

## Scrub
- 발표 스터디를 통해 STT → LLM 파이프라인 상태 점검
- 멀티프로세싱 / 멀티스레딩 비교 및 아키텍처 최적화 아이디어 정리
- 서비스 모니터링 툴 체계 검토 (Prometheus, Grafana, Metabase, LangFuse 등)
- 실험/운영 단계별 도구 적용 전략 고민

## Learned

### 파이프라인 구조 현황 및 확장성
- 현재 service layer 구조 깔끔하게 분리됨
- WhisperX → STT → Gemini → 피드백 → DB 저장
- 현 시점에서 LangChain 도입 필수 아님
- 키워드 추출, 꼬리질문 등 복잡 로직 추가되면 체이닝 도입 고려 가능

### 멀티프로세싱 vs 멀티스레딩

| 비교 항목 | 멀티프로세싱 | 멀티스레딩 |
|---|---|---|
| 사용 리소스 | 프로세스 분리 (독립 메모리) | 스레드 공유 (메모리 효율적) |
| 모델 로드 | 프로세스별 중복 로드 발생 | 메모리 공유 가능 |
| WhisperX 적합성 | 모델 크기 클수록 부담 | GPU context 관리 용이 |
| 성능 이슈 | 프로세스 전환 오버헤드 존재 | 컨텍스트 스위칭 병목 가능 |

- WhisperX는 compute-heavy 구조로 스레드 효율이 더 유리한 경우가 많음
- GPU context switching은 스케줄링 최적화 필요 (vLLM, Triton 참고)

### 모니터링 체계 정리

| 툴 | 목적 | 특징 |
|---|---|---|
| Prometheus + Grafana | 시스템 모니터링 | 서버 부하, GPU 사용률, 응답시간 등 |
| Metabase | 도메인 품질 모니터링 | STT 정확도, LLM 피드백 품질 등 |
| LangFuse | 운영 품질 추적 | 로그, 프롬프트 품질 관리 |

- 실험 단계에서는 psutil, nvidia-smi, wandb 등 경량화 모니터링 사용
- 운영 단계에서는 Prometheus + Grafana 본격 도입

### LLM 서빙 관리 툴 비교

| 도구 | 주요 용도 | 적합 시점 |
|---|---|---|
| LangChain | 파이프라인 체이닝 | 실험 복잡도 증가 시 |
| LangSmith | 프롬프트 평가/실험 | prompt tuning 다수 시 |
| LangFuse | 운영 모니터링 | 서비스 안정화 시 |

### 확장 설계 방향성 요약
- 현재 구조 기반으로 실험과 운영 간 전환 부담이 낮음
- LangFuse와 Prometheus 조합으로 운영 품질 안정화 가능
- 멀티프로세스 및 멀티스레딩 병행 설계 가능성 확보
- vLLM 스케줄링 구조 도입 가능성 있음

## Keep
- 현재 service layer 기반 파이프라인 구조 유지
- 실험과 운영을 고려한 모니터링 및 서빙 구조 설계 능력 확보

## Problem
- 멀티프로세스, 멀티스레드 최적 경계선에 대한 실험 데이터 부족
- 실 운영에 적용하기 위한 초기 스케폴딩 설계 미흡

## Try
- LangFuse 운영 적용 베타 도입 검토

## 참고자료
