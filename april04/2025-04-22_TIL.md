# Today - 2025-04-22 (Tue)

## Scrub
- STT 기반 면접 피드백 생성 모듈을 위한 AI 서빙 아키텍처 설계도 작성
- 실사용 환경을 반영한 STT 모델 성능 실험 계획 수립
- FastAPI 기반 AI 서버와 BE 간의 통신 흐름을 고려한 비동기 처리 구조 설계

---

## Learned

### 시스템 구조 설계: STT + 피드백 생성 워크플로우

**구성요소 요약**

| 구성 요소     | 설명                                                  |
|--------------|-------------------------------------------------------|
| BE           | 음성 업로드 및 결과 저장, API Gateway와 통신         |
| API Gateway  | AI 서버에 피드백 요청, 결과 수신 후 BE로 전달        |
| STT 모델      | 음성을 텍스트로 변환 (Whisper 등)                     |
| LLM 모델      | STT 텍스트를 요약 및 피드백 생성                      |
| RDB (임시 저장) | 텍스트 및 피드백 임시 저장 및 실패 대비 백업         |
| AWS S3       | 면접 음성 파일 저장소                                 |

---

## Experiment Plan

### 3. STT 기반 피드백 시스템 실험 설계

#### 3-1. 실험 설계 개요

| 항목        | 설명                                                |
|-------------|-----------------------------------------------------|
| 목적        | STT 정확도 향상 및 실시간 대응을 위한 모델 평가    |
| 서버 환경    | FastAPI 기반 추론 서버                               |
| GPU 환경     | Colab Pro (T4, L4), GCP Compute (L4 기준)           |
| 주요 도구    | psutil, nvidia-smi, Google WER, Python logging      |
| 테스트 방식  | HTTP Multipart를 통한 실시간 요청 방식              |

#### 3-2. 실험 1단계: 공개 데이터셋 기반

- 데이터셋: [AIHub ICT 면접 음성 데이터셋](https://aihub.or.kr/aihubdata/data/view.do?dataSetSn=71592)
- 데이터 구성: 면접 질문 + 응답 (30초~1분)
- 측정 항목:
  - 처리 시간
  - Word Error Rate (WER)
  - GPU 자원 사용량
  - 에러 유형 (잘림, 공백 삽입 등)

#### 3-3. 실험 2단계: 실면접 기반 실측 실험

| 항목        | 설명                                         |
|-------------|----------------------------------------------|
| 데이터      | 실면접 녹음 (총 40분, 5개 팀)                |
| 저장 위치    | Google Drive                                |
| 처리 방식    | 음성 → STT → 요약 생성                       |
| 측정 항목    | 전체 처리 시간, 문장 분리 정확도, API 안정성 등 |

#### 3-4. 성능 비교 기록 양식 (실험 후 입력)

| 항목                | 공개 데이터 (AIHub) | 실면접 데이터 |
|---------------------|---------------------|----------------|
| 평균 추론 시간       | TBD                 | TBD            |
| WER (%)             | TBD                 | TBD            |
| 메모리 사용량        | TBD                 | TBD            |
| 문장 분리 정확도     | TBD                 | TBD            |
| 특이사항            | TBD                 | TBD            |

#### 3-5. 최적화 전략

| 전략                    | 설명                                                  |
|-------------------------|-------------------------------------------------------|
| Whisper 베이스 모델 선정 | 정확도(WER), 지연 시간, 안정성 기준으로 선정         |
| 후처리 자동화           | 문장 단위 분할 + 구두점 삽입 등 후처리 정제 자동화   |

#### 3-6. 향후 계획

- 실험 완료 후, 성능을 기준으로 최종 모델 선택
- Whisper → GCP Cloud Run 기반 서빙 시스템 전환
- 피드백 요약 품질 개선을 위한 후처리 모듈 정교화

---

## Keep
- 실시간 연산이 어려운 환경을 고려한 비동기 설계 기반 구조
- 실데이터와 공개데이터를 단계별 실험으로 나누어 비교 가능하게 한 점

## Problem
- STT 후처리 정확도와 문장 분리 실패 케이스에 대한 평가기준 미흡
- 모델별 GPU 자원 사용률 비교 필요 (성능 ↔ 자원 효율 트레이드오프)

## Try
- Whisper 모델 외에도 Google STT API 실험 포함 예정