# Today - 2025-03-26 (Wed)

## Scrub
- CNN 기반 꽃 이미지 분류 보고서 중간 점검 및 실험 결과 정제
- 특히 VGG16 기반 파인튜닝 전략의 구조적 서술 보강 및 시각화 기반 설명 강화

## Learned

###  Fine-Tuning 전략 정리 및 명확화
- 기존에 단순히 "VGG16의 마지막 층을 일부 해제하여 학습했다"는 수준의 설명에서 벗어나,
  - Conv Block5만을 해제하고 하위 블록은 고정한 이유,
  - 일반적으로 전이학습 시 **Feature Extractor → Discriminative Layer**로의 구분이 존재하며,
  - 꽃 이미지 분류와 같이 데이터 수가 적은 경우, 하위 계층은 일반적인 엣지/텍스처 특성 유지가 유리하다는 점을 근거로 정리
- `include_top=False`, `trainable=True` 설정의 의미를 기술적으로 설명

### 실험 자동화 코드 설명 연동
- 모델 구조 정의 및 학습 루프 구현부에서 사용된 `ImageDataGenerator`, `ModelCheckpoint`, `EarlyStopping` 등의 주요 구성 요소에 대한 역할 설명 추가
- 특히 `ReduceLROnPlateau`가 validation loss의 plateau 상태에 반응하여 학습률을 조절하며 **Local Minima 탈출에 기여**함을 서술

### 성능 해석 방식 개선
- 단순 Accuracy 수치 비교에서 벗어나,
  - **Training vs Validation 곡선 비교**,
  - Epoch 진행 시점에 따른 loss의 급변 현상,
  - 과적합 방지 기법의 실질적 효과를 분석적으로 정리
- `history` 객체 기반 그래프를 부록이 아닌 본문에서 직접 인용하여 해석 주도

## Keep
- 모델 학습 결과를 단순 지표로 제시하는 것이 아니라, **모델 설계 결정 → 실험 조건 구성 → 결과 해석**의 구조로 연결하여 논리 흐름 유지
- 파인튜닝 계층 설정과 학습률 조정 전략을 기술적으로 설득력 있게 구성한 방향 유지

## Problem
- 일부 도표가 설명과 분리되어 배치되어 있어 독립적인 해석이 어려움
- 성능 지표의 수치 해석이 서술형으로만 정리되어 시각적 명확성이 부족

## Try
- 실험 결과 그래프를 표 형식과 병기하며, 각 시각화에 대한 **정성적 해석 주석**을 별도 부연할 것
- “왜 이 계층을 학습시켰는가?”, “어떤 조건에서 성능이 튀는가?”에 대한 질문에 스스로 답할 수 있도록,
  - 각 실험 설계의 목적과 결과 간 인과 관계를 명시적으로 드러내는 글쓰기 방향 유지

## 참고자료
- [Transfer Learning with Keras Applications](https://keras.io/api/applications/)
- [Fine-Tuning Strategy in Small Dataset Scenarios](https://cs231n.github.io/transfer-learning/)
- [EarlyStopping & ReduceLROnPlateau 공식 문서](https://keras.io/api/callbacks/)